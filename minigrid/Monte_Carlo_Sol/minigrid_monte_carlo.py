import gym
import numpy as np 
import random
import matplotlib.pyplot as plt
import minigrid
import time



policy={}
P={((1,1),0) : {0:1/3,1:1/3,2:1/3}, ((1,1),1) : {0:1/3,1:1/3,2:1/3}, ((1,1),2) : {0:1/3,1:1/3,2:1/3}, ((1,1),3) : {0:1/3,1:1/3,2:1/3}, ((1,2),0) : {0:1/3,1:1/3,2:1/3}, ((1,2),1) : {0:1/3,1:1/3,2:1/3}, ((1,2),2) : {0:1/3,1:1/3,2:1/3}, ((1,2),3) : {0:1/3,1:1/3,2:1/3}, ((1,3),0) : {0:1/3,1:1/3,2:1/3}, ((1,3),1) : {0:1/3,1:1/3,2:1/3}, ((1,3),2) : {0:1/3,1:1/3,2:1/3}, ((1,3),3) : {0:1/3,1:1/3,2:1/3}, ((1,4),0) : {0:1/3,1:1/3,2:1/3}, ((1,4),1) : {0:1/3,1:1/3,2:1/3}, ((1,4),2) : {0:1/3,1:1/3,2:1/3}, ((1,4),3) : {0:1/3,1:1/3,2:1/3}, ((2,1),0) : {0:1/3,1:1/3,2:1/3}, ((2,1),1) : {0:1/3,1:1/3,2:1/3}, ((2,1),2) : {0:1/3,1:1/3,2:1/3}, ((2,1),3) : {0:1/3,1:1/3,2:1/3}, ((2,2),0) : {0:1/3,1:1/3,2:1/3}, ((2,2),1) : {0:1/3,1:1/3,2:1/3}, ((2,2),2) : {0:1/3,1:1/3,2:1/3}, ((2,2),3) : {0:1/3,1:1/3,2:1/3}, ((2,3),0) : {0:1/3,1:1/3,2:1/3}, ((2,3),1) : {0:1/3,1:1/3,2:1/3}, ((2,3),2) : {0:1/3,1:1/3,2:1/3}, ((2,3),3) : {0:1/3,1:1/3,2:1/3}, ((2,4),0) : {0:1/3,1:1/3,2:1/3}, ((2,4),1) : {0:1/3,1:1/3,2:1/3}, ((2,4),2) : {0:1/3,1:1/3,2:1/3}, ((2,4),3) : {0:1/3,1:1/3,2:1/3}, ((3,1),0) : {0:1/3,1:1/3,2:1/3}, ((3,1),1) : {0:1/3,1:1/3,2:1/3}, ((3,1),2) : {0:1/3,1:1/3,2:1/3}, ((3,1),3) : {0:1/3,1:1/3,2:1/3}, ((3,2),0) : {0:1/3,1:1/3,2:1/3}, ((3,2),1) : {0:1/3,1:1/3,2:1/3}, ((3,2),2) : {0:1/3,1:1/3,2:1/3}, ((3,2),3) : {0:1/3,1:1/3,2:1/3}, ((3,3),0) : {0:1/3,1:1/3,2:1/3}, ((3,3),1) : {0:1/3,1:1/3,2:1/3}, ((3,3),2) : {0:1/3,1:1/3,2:1/3}, ((3,3),3) : {0:1/3,1:1/3,2:1/3}, ((3,4),0) : {0:1/3,1:1/3,2:1/3}, ((3,4),1) : {0:1/3,1:1/3,2:1/3}, ((3,4),2) : {0:1/3,1:1/3,2:1/3}, ((3,4),3) : {0:1/3,1:1/3,2:1/3}, ((4,1),0) : {0:1/3,1:1/3,2:1/3}, ((4,1),1) : {0:1/3,1:1/3,2:1/3}, ((4,1),2) : {0:1/3,1:1/3,2:1/3}, ((4,1),3) : {0:1/3,1:1/3,2:1/3}, ((4,2),0) : {0:1/3,1:1/3,2:1/3}, ((4,2),1) : {0:1/3,1:1/3,2:1/3}, ((4,2),2) : {0:1/3,1:1/3,2:1/3}, ((4,2),3) : {0:1/3,1:1/3,2:1/3}, ((4,3),0) : {0:1/3,1:1/3,2:1/3}, ((4,3),1) : {0:1/3,1:1/3,2:1/3}, ((4,3),2) : {0:1/3,1:1/3,2:1/3}, ((4,3),3) : {0:1/3,1:1/3,2:1/3}, ((4,4),0) : {0:1/3,1:1/3,2:1/3}, ((4,4),1) : {0:1/3,1:1/3,2:1/3}, ((4,4),2) : {0:1/3,1:1/3,2:1/3}, ((4,4),3) : {0:1/3,1:1/3,2:1/3}}
q_values={((1,1),0) : {0:0,1:0,2:0}, ((1,1),1) : {0:0,1:0,2:0}, ((1,1),2) : {0:0,1:0,2:0}, ((1,1),3) : {0:0,1:0,2:0}, ((1,2),0) : {0:0,1:0,2:0}, ((1,2),1) : {0:0,1:0,2:0}, ((1,2),2) : {0:0,1:0,2:0}, ((1,2),3) : {0:0,1:0,2:0}, ((1,3),0) : {0:0,1:0,2:0}, ((1,3),1) : {0:0,1:0,2:0}, ((1,3),2) : {0:0,1:0,2:0}, ((1,3),3) : {0:0,1:0,2:0}, ((1,4),0) : {0:0,1:0,2:0}, ((1,4),1) : {0:0,1:0,2:0}, ((1,4),2) : {0:0,1:0,2:0}, ((1,4),3) : {0:0,1:0,2:0}, ((2,1),0) : {0:0,1:0,2:0}, ((2,1),1) : {0:0,1:0,2:0}, ((2,1),2) : {0:0,1:0,2:0}, ((2,1),3) : {0:0,1:0,2:0}, ((2,2),0) : {0:0,1:0,2:0}, ((2,2),1) : {0:0,1:0,2:0}, ((2,2),2) : {0:0,1:0,2:0}, ((2,2),3) : {0:0,1:0,2:0}, ((2,3),0) : {0:0,1:0,2:0}, ((2,3),1) : {0:0,1:0,2:0}, ((2,3),2) : {0:0,1:0,2:0}, ((2,3),3) : {0:0,1:0,2:0}, ((2,4),0) : {0:0,1:0,2:0}, ((2,4),1) : {0:0,1:0,2:0}, ((2,4),2) : {0:0,1:0,2:0}, ((2,4),3) : {0:0,1:0,2:0}, ((3,1),0) : {0:0,1:0,2:0}, ((3,1),1) : {0:0,1:0,2:0}, ((3,1),2) : {0:0,1:0,2:0}, ((3,1),3) : {0:0,1:0,2:0}, ((3,2),0) : {0:0,1:0,2:0}, ((3,2),1) : {0:0,1:0,2:0}, ((3,2),2) : {0:0,1:0,2:0}, ((3,2),3) : {0:0,1:0,2:0}, ((3,3),0) : {0:0,1:0,2:0}, ((3,3),1) : {0:0,1:0,2:0}, ((3,3),2) : {0:0,1:0,2:0}, ((3,3),3) : {0:0,1:0,2:0}, ((3,4),0) : {0:0,1:0,2:0}, ((3,4),1) : {0:0,1:0,2:0}, ((3,4),2) : {0:0,1:0,2:0}, ((3,4),3) : {0:0,1:0,2:0}, ((4,1),0) : {0:0,1:0,2:0}, ((4,1),1) : {0:0,1:0,2:0}, ((4,1),2) : {0:0,1:0,2:0}, ((4,1),3) : {0:0,1:0,2:0}, ((4,2),0) : {0:0,1:0,2:0}, ((4,2),1) : {0:0,1:0,2:0}, ((4,2),2) : {0:0,1:0,2:0}, ((4,2),3) : {0:0,1:0,2:0}, ((4,3),0) : {0:0,1:0,2:0}, ((4,3),1) : {0:0,1:0,2:0}, ((4,3),2) : {0:0,1:0,2:0}, ((4,3),3) : {0:0,1:0,2:0}, ((4,4),0) : {0:0,1:0,2:0}, ((4,4),1) : {0:0,1:0,2:0}, ((4,4),2) : {0:0,1:0,2:0}, ((4,4),3) : {0:0,1:0,2:0}}
nS=16
nA=3
max_steps=100
epi=200 

def epi_generator(env,policy,eps,nA,max_steps=150):
    env.reset()
    epi=[]
    k=0
    while True and k<=max_steps:
        env.render()
        state=((env.agent_pos),env.agent_dir)
        policy[state]=eps_greedy(eps,P,state)
        action=policy[state]
        _,reward,done,_,_=env.step(action)
        epi.append([state,action,reward,done])
        k+=1
        if done:
            break
    return epi,len(epi)-1







n={}
for x in range(1,5):
            for y in range(1,5):
                for z in range(4):
                    n[((x,y),z)]={0:0,1:0,2:0}

def MC_control(env,policy,epi,q_values,nA,n,gamma=0.8):
    total_return=[]
    steps=[]
    eps=1.0
    for epi_no in range(1,epi+1):
        traj, T = epi_generator(env, policy,eps,nA,max_steps)
        steps.append(T)
        eps=eps_decay(eps,epi_no)
        G=0.0
        for t in range (T,-1,-1):
            St,At,Rt_1,_ =traj[t]
            G=gamma*G+Rt_1
            n[St][At]+=1  #counting every visit to that state
            q_values[St][At]+=(G-q_values[St][At])/n[St][At]
            A=max(q_values[St], key=q_values[St].get)
            for a in range(nA):
                if a ==A :
                    P[St][a]=1-eps+eps/nA
                else:
                    P[St][a]=eps/nA
        total_return.append(G)
    return policy,q_values,P,steps,total_return







def eps_greedy(eps,P,state):
    r=random.random()
    action = None
    cumulative_prob = 0.0
    for a in range(3):
      cumulative_prob += P[state][a]
      if r <= cumulative_prob:
        action = a
        break
    return action


def eps_decay(eps,epi_no,min_eps=0.01 ):
    new_eps=1/epi_no
    return new_eps


def plotting(x,y,xname,yname,title):
    plt.figure()
    plt.plot(x,y)
    plt.title(title)
    plt.xlabel(xname)
    plt.ylabel(yname)
    plt.grid(True)
    plt.show()


env=gym.make('MiniGrid-Empty-6x6-v0')#,render_mode='human')

for state in P:
    policy[state]=eps_greedy(1,P,state)

initial=time.time()
policy,q_values,P,steps,total_return = MC_control(env,policy,epi,q_values,nA,n,gamma=0.9)
final=time.time()
duration=final-initial
episode=list(range(1,epi+1))
plotting(episode,steps,"episode","steps","Steps vs Episode")
plotting(episode,total_return,"episode","returns","Returns vs Episode")

print("Time taken: ",duration)
print("\n q_value: \n",q_values)
print("\n P: \n",P)
print("\n policy: \n",policy)
print("\n steps: \n ",steps)
print("\n returns: \n ",total_return)
print(f'\nNo. of episode: {epi}\nStep list length: {len(steps)}\nReturn list length: {len(total_return)}')


env.close()
